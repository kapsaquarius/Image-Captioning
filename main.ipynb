{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from dataset import MiniFlickrDataset, get_loader\n",
    "from todo import CaptioningModel\n",
    "from trainer import Trainer\n",
    "from lr_warmup import LRWarmup\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.data_path = 'dataset.pkl'\n",
    "        self.clip_model = 'openai/clip-vit-base-patch32'\n",
    "        self.text_model = 'gpt2'\n",
    "        self.seed = 100\n",
    "        self.num_workers = 0\n",
    "        self.train_size = 0.84\n",
    "        self.val_size = 0.13\n",
    "        self.test_size = 100\n",
    "        self.epochs = 10\n",
    "        self.lr = 3e-3\n",
    "        self.k = 0.33\n",
    "        self.batch_size_exp = 6\n",
    "        self.ep_len = 4\n",
    "        self.num_layers = 6\n",
    "        self.n_heads = 16\n",
    "        self.forward_expansion = 4\n",
    "        self.max_len = 40\n",
    "        self.dropout = 0.1\n",
    "config = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = utils.init_env(config.seed)\n",
    "\n",
    "# Create data loaders\n",
    "dataset = MiniFlickrDataset(config.data_path)\n",
    "config.train_size = int(config.train_size * len(dataset))\n",
    "config.val_size = len(dataset) - config.train_size - config.test_size\n",
    "train_dataset, val_dataoet, test_dataset = random_split(dataset, [config.train_size, config.val_size, config.test_size])\n",
    "train_loader = get_loader(\n",
    "    train_dataset, \n",
    "    bs_exp=config.batch_size_exp, \n",
    "    shuffle=True, \n",
    "    num_workers=config.num_workers,\n",
    "    pin_memory=True,\n",
    ")\n",
    "test_loader = get_loader(\n",
    "    test_dataset,\n",
    "    bs_exp=0,\n",
    "    shuffle=False,\n",
    "    num_workers=config.num_workers,\n",
    "    pin_memory=True,\n",
    "    train=False,\n",
    ")\n",
    "\n",
    "# Creat model\n",
    "model = CaptioningModel(\n",
    "    clip_model=config.clip_model,\n",
    "    text_model=config.text_model,\n",
    "    ep_len=config.ep_len,\n",
    "    num_layers=config.num_layers, \n",
    "    n_heads=config.n_heads, \n",
    "    forward_expansion=config.forward_expansion, \n",
    "    dropout=config.dropout, \n",
    "    max_len=config.max_len,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Create optimizer, lr scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
    "warmup = LRWarmup(epochs=config.epochs, max_lr=config.lr, k=config.k)\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, warmup.lr_warmup)\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    scaler=torch.cuda.amp.GradScaler(),\n",
    "    scheduler=scheduler,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# use _load_ckpt method of the trainer to load weights from the saved checkpoint to resume the training. Below is a sample code for the same\n",
    "\n",
    "#trainer._load_ckp(\"path to .pt file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "for epoch in range(trainer.epoch, config.epochs):\n",
    "    trainer.train_epoch()\n",
    "\n",
    "    score = trainer.test_epoch()\n",
    "    print(\"Score: {:.4f}\".format(score))\n",
    "\n",
    "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "    if (epoch + 1) % 3 == 0:\n",
    "        trainer.save_ckp(os.path.join(\"checkpoints\", f'epoch_{epoch + 1}.pt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
